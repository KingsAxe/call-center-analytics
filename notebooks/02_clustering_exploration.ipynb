{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d55e86-70ca-4315-9ea5-3a36faa246a9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Data Sanitization\n",
    "Before we vectorize the text, we must pass it through our TextSanitizer. This ensures that our embeddings are trained on the \"intent\" of the call rather than being biased by specific PII like unique names or account IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9808e05c-d488-4154-9bbd-9c8f837c0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Desktop\\Pro_Jets\\call-center-analytics\\call-center-analytics\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "from src.preprocessing.cleaner import TextSanitizer\n",
    "from src.features.embeddings import VectorEngine\n",
    "import umap\n",
    "import hdbscan\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88717615-ea47-43c0-8ec2-ad200716258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Program Files\\\\Python312\\\\python312.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b203b34-a859-4def-9607-1d571a9604c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39mTraceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Pro_Jets\\call-center-analytics\\src\\preprocessing\\cleaner.py:9\u001b[39m, in \u001b[36mTextSanitizer.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[38;5;28mself\u001b[39m.nlp = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men_core_web_sm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Fallback if model isn't downloaded\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Pro_Jets\\call-center-analytics\\call-center-analytics\\Lib\\site-packages\\spacy\\__init__.py:52\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03mname (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m \u001b[33;03mRETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Pro_Jets\\call-center-analytics\\call-center-analytics\\Lib\\site-packages\\spacy\\util.py:531\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E050.format(name=name))\n",
      "\u001b[31mOSError\u001b[39m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mOSError\u001b[39mTraceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize our custom modules\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m sanitizer = \u001b[43mTextSanitizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m vector_engine = VectorEngine()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Apply PII Redaction\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Pro_Jets\\call-center-analytics\\src\\preprocessing\\cleaner.py:14\u001b[39m, in \u001b[36mTextSanitizer.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     13\u001b[39m os.system(\u001b[33m\"\u001b[39m\u001b[33mpython -m spacy download en_core_web_sm\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28mself\u001b[39m.nlp = \u001b[43mspacy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43men_core_web_sm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Pro_Jets\\call-center-analytics\\call-center-analytics\\Lib\\site-packages\\spacy\\__init__.py:52\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\n\u001b[32m     29\u001b[39m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[32m     30\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m     35\u001b[39m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] = util.SimpleFrozenDict(),\n\u001b[32m     36\u001b[39m ) -> Language:\n\u001b[32m     37\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     50\u001b[39m \u001b[33;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Pro_Jets\\call-center-analytics\\call-center-analytics\\Lib\\site-packages\\spacy\\util.py:531\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, vocab, disable, enable, exclude, config)\u001b[39m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E941.format(name=name, full=OLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m531\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors.E050.format(name=name))\n",
      "\u001b[31mOSError\u001b[39m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "# Initialize our custom modules\n",
    "sanitizer = TextSanitizer()\n",
    "vector_engine = VectorEngine()\n",
    "\n",
    "# Apply PII Redaction\n",
    "print(\"Redacting PII and cleaning text...\")\n",
    "processed_df['sanitized_text'] = processed_df['clean_text'].apply(sanitizer.redact_pii)\n",
    "processed_df['sanitized_text'] = processed_df['sanitized_text'].apply(sanitizer.clean_transcript)\n",
    "\n",
    "processed_df[['clean_text', 'sanitized_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b059c6-2805-40e2-a013-d38fd3e7c3ef",
   "metadata": {},
   "source": [
    "### 2. High-Dimensional Vectorization using Transformers\n",
    "We now convert the sanitized text into 768-dimensional dense vectors using the all-mpnet-base-v2 transformer. These embeddings capture semantic meaning—mapping \"I want to leave\" and \"Cancel my subscription\" to the same vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc391a30-6486-4171-9899-38e52f7f2931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Embeddings\n",
    "# In a production pipeline, you would cache these to 'data/embeddings/' \n",
    "embeddings = vector_engine.generate_embeddings(processed_df['sanitized_text'].tolist())\n",
    "\n",
    "print(f\"Embedding Matrix Shape: {embeddings.shape}\")\n",
    "# Save for later use to avoid re-computing\n",
    "np.save('data/embeddings/transcript_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1ff07f-5348-4a30-b481-429927e6430e",
   "metadata": {},
   "source": [
    "### 3. Dimensionality Reduction for Cluster Stability (UMAP)\n",
    "Clustering algorithms like HDBSCAN struggle with the \"Curse of Dimensionality\" in 768D space. We use UMAP (Uniform Manifold Approximation and Projection) to compress our embeddings into 5-10 dimensions, preserving the \"local neighborhoods\" of similar calls while making the density visible to the clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee59b05-83b3-4c05-8369-4b4489e28735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions for better clustering performance\n",
    "reducer = umap.UMAP(\n",
    "    n_neighbors=15, \n",
    "    n_components=5, \n",
    "    metric='cosine', \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "umap_embeddings = reducer.fit_transform(embeddings)\n",
    "print(f\"Reduced Embeddings Shape: {umap_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5809254a-8e53-446c-9ad6-245ce05776b9",
   "metadata": {},
   "source": [
    "### 4. Latent Intent Discovery with HDBSCAN\n",
    "Unlike K-Means, we don't guess the number of clusters. HDBSCAN finds \"islands of high density\" in the data. Any call that is too unique to fit a pattern is labeled as -1 (Noise), which is perfect for identifying one-off edge cases that need human review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ced40c4-ac46-4071-98a5-536978113c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure HDBSCAN\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=15, \n",
    "    min_samples=5, \n",
    "    metric='euclidean', \n",
    "    cluster_selection_method='eom'\n",
    ")\n",
    "\n",
    "processed_df['cluster_id'] = clusterer.fit_predict(umap_embeddings)\n",
    "\n",
    "# Check cluster distribution\n",
    "print(processed_df['cluster_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e32a377-09fb-4154-96af-2b6d22d9df97",
   "metadata": {},
   "source": [
    "### 5. Visualizing the Call Archetypes\n",
    "To make our findings \"stakeholder-ready,\" we project the clusters into 2D space. This visualization allows managers to see the \"thematic clusters\" of their call center—where Billing issues end and Technical Support begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896b468-482e-427e-8fb8-ee96a7223e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D for visualization only\n",
    "viz_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "viz_embeddings = viz_reducer.fit_transform(embeddings)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(\n",
    "    viz_embeddings[:, 0], \n",
    "    viz_embeddings[:, 1], \n",
    "    c=processed_df['cluster_id'], \n",
    "    cmap='Spectral', \n",
    "    s=50, \n",
    "    alpha=0.6\n",
    ")\n",
    "plt.colorbar(scatter, label='Cluster ID')\n",
    "plt.title('Call Center Intent Archetypes (UMAP Projection)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1bab88-5dd4-443c-bf43-8c3fe031518c",
   "metadata": {},
   "source": [
    "### 6. Archetype Interpretation: Mapping Clusters to Strategy\n",
    "The final step is translating Cluster IDs back into business terms. We examine the top words and average metrics (Talk Ratio, CSAT) for each cluster to name them (e.g., \"The Churn Risk Group\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f538717-46de-47dc-b292-c75ec875f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by cluster to see behavioral signatures\n",
    "cluster_profile = processed_df.groupby('cluster_id').agg({\n",
    "    'talk_ratio': 'mean',\n",
    "    'csat_score': 'mean',\n",
    "    'duration_sec': 'mean',\n",
    "    'escalated': 'mean',\n",
    "    'clean_text': 'count'\n",
    "}).rename(columns={'clean_text': 'volume'})\n",
    "\n",
    "print(\"--- Cluster Behavioral Profiles ---\")\n",
    "cluster_profile.sort_values(by='csat_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840cfb4f-e242-49ad-9989-1dd71ec5d827",
   "metadata": {},
   "source": [
    "Production Pipeline: Multi-stage NLP pipeline (Clean -> Embed -> Reduce -> Cluster).\n",
    "\n",
    "Advanced Architecture: You utilized Transformers and Density-Based Clustering.\n",
    "\n",
    "Scalability: You’ve implemented caching for embeddings and used algorithms that handle large datasets efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62725373-010f-4941-9ce4-b84047114bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6352403-e4fe-473a-99d4-552d491b8bac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4996ad66-96d2-4240-bd64-80c50c5f0a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e3237c-68b9-49bf-80fe-0ca64013c927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78de485d-7f04-408f-8f43-0053c7184ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Call Center Analytics",
   "language": "python",
   "name": "call-center-analytics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
