{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89d55e86-70ca-4315-9ea5-3a36faa246a9",
   "metadata": {},
   "source": [
    "## 1. Environment Setup & Data Sanitization\n",
    "Before we vectorize the text, we must pass it through our TextSanitizer. This ensures that our embeddings are trained on the \"intent\" of the call rather than being biased by specific PII like unique names or account IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9808e05c-d488-4154-9bbd-9c8f837c0a2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcleaner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TextSanitizer\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorEngine\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "from src.preprocessing.cleaner import TextSanitizer\n",
    "from src.features.embeddings import VectorEngine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Initialize our custom modules\n",
    "sanitizer = TextSanitizer()\n",
    "vector_engine = VectorEngine()\n",
    "\n",
    "# Apply PII Redaction\n",
    "print(\"Redacting PII and cleaning text...\")\n",
    "processed_df['sanitized_text'] = processed_df['clean_text'].apply(sanitizer.redact_pii)\n",
    "processed_df['sanitized_text'] = processed_df['sanitized_text'].apply(sanitizer.clean_transcript)\n",
    "\n",
    "processed_df[['clean_text', 'sanitized_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e04a2d4-7e19-45c6-a20e-ff4851c6a14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
